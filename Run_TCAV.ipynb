{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v88fM4ciYYde"
   },
   "source": [
    "# Running TCAV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-RlU8wNYYdj"
   },
   "source": [
    "This notebook walks you through an example application of the TCAV library step-by-step to understand which human interpretable concepts (e.g. stripes, dots, zigzags) are important to the image classifier GoogleNet's (a.k.a. Inception v1) prediction of Zebras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1zIj8-aYYdj"
   },
   "source": [
    "## Install required packages\n",
    "\n",
    "To run through this notebook in the interim, you are encouraged to utilize a `virtualenv` or `conda` environment for installing and working with the required packages to avoid any dependency and compatability issues with different versions of packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sIHww5CuYYdk",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\andre\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (22.10.26)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tcav in c:\\users\\andre\\anaconda3\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tcav) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tcav) (1.0.2)\n",
      "Requirement already satisfied: protobuf>=3.10.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tcav) (3.19.1)\n",
      "Requirement already satisfied: Pillow>=6.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tcav) (9.0.1)\n",
      "Requirement already satisfied: matplotlib>=2.2.4 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tcav) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.4->tcav) (1.21.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.4->tcav) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.4->tcav) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.4->tcav) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.4->tcav) (3.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.4->tcav) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.4->tcav) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2.4->tcav) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.3->tcav) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.3->tcav) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "%pip install tcav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NT91qkMYYdk"
   },
   "source": [
    "## Download example models and images\n",
    "\n",
    "Open a terminal and run the following commands:\n",
    "\n",
    "```\n",
    "cd tcav/tcav_examples/image_models/imagenet\n",
    "\n",
    "python download_and_make_datasets.py --source_dir=YOUR_PATH --number_of_images_per_folder=50 --number_of_random_folders=3\n",
    "```\n",
    "\n",
    "This script will download the following content into separate folders into a directory you specify with the `--source_dir=` argument:\n",
    "\n",
    "**Images**\n",
    "*  ImageNet images for the target Zebra class\n",
    "*  [Broden dataset](http://netdissect.csail.mit.edu/) images for three concepts (e.g. striped, dotted, zigzagged)\n",
    "*  Random ImageNet class images used by TCAV for hypothesis testing of important concepts\n",
    "\n",
    "**Models**\n",
    "*  [Inception 5h model](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/inception5h.py)\n",
    "*  [Mobilenet V2 model](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlrLUu4zYYdl"
   },
   "source": [
    "## Import extensions and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sS1ZjSZjYYdl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "U4yP9kDlYYdl"
   },
   "outputs": [],
   "source": [
    "import tcav.activation_generator as act_gen\n",
    "import tcav.cav as cav\n",
    "import tcav.model  as model\n",
    "import tcav.tcav as tcav\n",
    "import tcav.utils as utils\n",
    "import tcav.utils_plot as utils_plot # utils_plot requires matplotlib\n",
    "import os \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yitpnXmEYYdm"
   },
   "source": [
    "## TCAV step-by-step\n",
    "\n",
    "You will walk through the following steps below:\n",
    "\n",
    "1. **Store example images in each folder** (you have this if you ran the above)\n",
    " * images for each concept\n",
    " * images for the class/labels of interest\n",
    " * random images that will be negative examples when learning CAVs (images that probably don't belong to any concepts)\n",
    "2. **Write a model wrapper** (below uses example from tcav/model.py)\n",
    " * an instance of  ModelWrapper abstract class (in model.py). This tells TCAV class (tcav.py) how to communicate with your model (e.g., getting internal tensors)\n",
    "3. **Retrieve model activations** (below uses example from tcav/activation_generator.py)\n",
    " * an instance of ActivationGeneratorInterface that tells TCAV class how to load example data and how to get activations from the model\n",
    "4. Run TCAV and visualize scores for important concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjjLK3pBYYdm"
   },
   "source": [
    "## Step 1: Store concept and target class images to local folders\n",
    "\n",
    "... and tell TCAV where they are.\n",
    "\n",
    "**source_dir**: where images of concepts, target class and random images (negative samples when learning CAVs) live. Each should be a sub-folder within this directory.\n",
    "\n",
    "Note that random image directories can be in any name. In this example, we are using `random500_0`, `random500_1`,.. for an arbitrary reason. \n",
    "\n",
    "You need roughly 50-200 images per concept and target class (10-20 pictures also tend to work, but 200 is pretty safe).\n",
    "\n",
    "\n",
    "**cav_dir**: directory to store CAVs (`None` if you don't want to store)\n",
    "\n",
    "**target, concept**: names of the target class (that you want to investigate) and concepts (strings) - these are folder names in source_dir\n",
    "\n",
    "**bottlenecks**: list of bottleneck names (intermediate layers in your model) that you want to use for TCAV. These names are defined in the model wrapper below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EHabMnMNYYdm",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMEMBER TO UPDATE YOUR_PATH (where images, models are)!\n"
     ]
    }
   ],
   "source": [
    "print ('REMEMBER TO UPDATE YOUR_PATH (where images, models are)!')\n",
    "\n",
    "# This is the name of your model wrapper (InceptionV3 and GoogleNet are provided in model.py)\n",
    "model_to_run = 'GoogleNet'  \n",
    "user = 'andre' #updated\n",
    "# the name of the parent directory that results are stored (only if you want to cache)\n",
    "project_name = 'tcav_class_test2'\n",
    "working_dir = \"/tmp/\" + user + '/' + project_name\n",
    "# where activations are stored (only if your act_gen_wrapper does so)\n",
    "activation_dir =  working_dir+ '/activations/'\n",
    "# where CAVs are stored. \n",
    "# You can say None if you don't wish to store any.\n",
    "cav_dir = working_dir + '/cavs/'\n",
    "# where the images live.\n",
    "\n",
    "# TODO: replace 'YOUR_PATH' with path to downloaded models and images. \n",
    "source_dir = \"C:/Users/andre/OneDrive/Skrivebord/TCAV_Deep_Learning\"\n",
    "bottlenecks = [ 'mixed4d']  # @param mixed4c\n",
    "\n",
    "layer_names = ['conv2d0', 'conv2d1', 'conv2d2',\n",
    "                'mixed3a', 'mixed3b',\n",
    "                'mixed4a', 'mixed4b', 'mixed4c', 'mixed4d', 'mixed4e',\n",
    "                'mixed5a', 'mixed5b']\n",
    "      \n",
    "utils.make_dir_if_not_exists(activation_dir)\n",
    "utils.make_dir_if_not_exists(working_dir)\n",
    "utils.make_dir_if_not_exists(cav_dir)\n",
    "\n",
    "# this is a regularizer penalty parameter for linear classifier to get CAVs. \n",
    "alphas = [0.1]   \n",
    "\n",
    "target = 'zebra'  \n",
    "concepts = [\"dotted\"]#,\"striped\",\"zigzagged\"]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(source_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_DfQqsAYYdn"
   },
   "source": [
    "## Step 2: Write your model wrapper\n",
    "\n",
    "The next step is to tell TCAV how to communicate with your model. See `model.GoogleNetWrapper_public ` for details.\n",
    "\n",
    "You can define a subclass of ModelWrapper abstract class to do this. Let me walk you thru what each function does (tho they are pretty self-explanatory).  This wrapper includes a lot of the functions that you already have, for example, `get_prediction`.\n",
    "\n",
    "### 2.1: Tensors from the graph: bottleneck tensors and ends\n",
    "First, store your bottleneck tensors in `self.bottlenecks_tensors` as a dictionary. You only need bottlenecks that you are interested in running TCAV with. Similarly, fill in `self.ends` dictionary with `input`, `logit` and `prediction` tensors.\n",
    "\n",
    "### 2.2: Define loss\n",
    "Get your loss tensor, and assigned it to `self.loss`. This is what TCAV uses to take directional derivatives. \n",
    "\n",
    "While doing so, you would also want to set \n",
    "```python\n",
    "self.y_input \n",
    "```\n",
    "this simply is a tensorflow place holder for the target index in the logit layer (e.g., 0 index for a dog, 1 for a cat).\n",
    "For multi-class classification, typically something like this works:\n",
    "\n",
    "```python\n",
    "self.y_input = tf.placeholder(tf.int64, shape=[None])\n",
    "```\n",
    "\n",
    "For example, for a multiclass classifier, something like below would work. \n",
    "\n",
    "```python\n",
    "    # Construct gradient ops.\n",
    "    with g.as_default():\n",
    "      self.y_input = tf.placeholder(tf.int64, shape=[None])\n",
    "\n",
    "      self.pred = tf.expand_dims(self.ends['prediction'][0], 0)\n",
    "\n",
    "      self.loss = tf.reduce_mean(\n",
    "          tf.nn.softmax_cross_entropy_with_logits(\n",
    "              labels=tf.one_hot(self.y_input, len(self.labels)),\n",
    "              logits=self.pred))\n",
    "    self._make_gradient_tensors()\n",
    "```\n",
    "\n",
    "### 2.3: Call _make_gradient_tensors in __init__() of your wrapper\n",
    "```python\n",
    "_make_gradient_tensors()  \n",
    "```\n",
    "does what you expect - given the loss and bottleneck tensors defined above, it adds gradient tensors.\n",
    "\n",
    "### 2.4: Fill in labels, image shapes and a model name.\n",
    "Get the mapping from labels (strings) to indice in the logit layer (int) in a dictionary format.\n",
    "\n",
    "```python\n",
    "def id_to_label(self, idx)\n",
    "def label_to_id(self, label)\n",
    "```\n",
    "\n",
    "Set your input image shape at  `self.image_shape`\n",
    "\n",
    "\n",
    "Set your model name to `self.model_name`\n",
    "\n",
    "You are done with writing the model wrapper! See the two example model wrapers, InceptionV3 and Googlenet in `tcav/model.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hH-YQiEIYYdn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create TensorFlow session.\n",
    "sess = utils.create_session()\n",
    "\n",
    "# GRAPH_PATH is where the trained model is stored.\n",
    "GRAPH_PATH = source_dir + \"/pretrained_model/inception5h/tensorflow_inception_graph.pb\"\n",
    "# LABEL_PATH is where the labels are stored. Each line contains one class, and they are ordered with respect to their index in \n",
    "# the logit layer. (yes, id_to_label function in the model wrapper reads from this file.)\n",
    "# For example, imagenet_comp_graph_label_strings.txt looks like:\n",
    "# dummy                                                                                      \n",
    "# kit fox\n",
    "# English setter\n",
    "# Siberian husky ...\n",
    "\n",
    "LABEL_PATH = source_dir + \"/pretrained_model/inception5h/imagenet_comp_graph_label_strings.txt\"\n",
    "\n",
    "mymodel = model.GoogleNetWrapper_public(sess,\n",
    "                                        GRAPH_PATH,\n",
    "                                        LABEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yY5kXbVAYYdo"
   },
   "source": [
    "## Step 3: Implement a class that returns activations (maybe with caching!)\n",
    "\n",
    "Lastly, you will implement a class of the ActivationGenerationInterface which TCAV uses to load example data for a given concept or target, call into your model wrapper and return activations. I pulled out this logic outside of mymodel because this step often takes the longest. By making it modular, you can cache your activations and/or parallelize your computations, as I have done in `ActivationGeneratorBase.process_and_load_activations` in `activation_generator.py`.\n",
    "\n",
    "\n",
    "The `process_and_load_activations` method of the activation generator must return a dictionary of activations that has concept or target name as  a first key, and the bottleneck name as a second key. So something like:\n",
    "\n",
    "```python\n",
    "{concept1: {bottleneck1: [[0.2, 0.1, ....]]},\n",
    "concept2: {bottleneck1: [[0.1, 0.02, ....]]},\n",
    "target1: {bottleneck1: [[0.02, 0.99, ....]]}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZmSyFxQbYYdo"
   },
   "outputs": [],
   "source": [
    "act_generator = act_gen.ImageActivationGenerator(mymodel, source_dir+'/concepts', activation_dir, max_examples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uABCWhp8YYdo"
   },
   "source": [
    "## Step 4: Run TCAV and visualize concept importance\n",
    "\n",
    "You are now ready to run TCAV! Let's do it.\n",
    "\n",
    "**num_random_exp**: number of experiments to confirm meaningful concept direction. TCAV will search for this many folders named `random500_0`, `random500_1`, etc. You can alternatively set the `random_concepts` keyword to be a list of folders of random concepts. Run at least 10-20 for meaningful tests. \n",
    "\n",
    "**random_counterpart**: as well as the above, you can optionally supply a single folder with random images as the \"positive set\" for statistical testing. Reduces computation time at the cost of less reliable random TCAV scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "F2FVOGSvYYdp",
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:mixed4d ['dotted', 'random500_0'] zebra 0.1\n",
      "INFO:tensorflow:mixed4d ['dotted', 'random500_1'] zebra 0.1\n",
      "INFO:tensorflow:mixed4d ['random500_0', 'random500_1'] zebra 0.1\n",
      "INFO:tensorflow:mixed4d ['random500_1', 'random500_0'] zebra 0.1\n",
      "INFO:tensorflow:TCAV will 4 params\n",
      "This may take a while... Go get coffee!\n",
      "INFO:tensorflow:running 4 params\n",
      "INFO:tensorflow:Running param 0 of 4\n",
      "INFO:tensorflow:running zebra ['dotted', 'random500_0']\n",
      "INFO:tensorflow:/tmp/andre/tcav_class_test2/activations/acts_dotted_mixed4d does not exist, Making one...\n",
      "INFO:tensorflow:/tmp/andre/tcav_class_test2/activations/acts_random500_0_mixed4d does not exist, Making one...\n",
      "INFO:tensorflow:/tmp/andre/tcav_class_test2/activations/acts_zebra_mixed4d does not exist, Making one...\n",
      "INFO:tensorflow:Training CAV ['dotted', 'random500_0'] - mixed4d alpha 0.1\n",
      "INFO:tensorflow:training with alpha=0.1\n",
      "INFO:tensorflow:acc per class {'dotted': 1.0, 'random500_0': 1.0, 'overall': 1.0}\n",
      "INFO:tensorflow:CAV accuracies: {'dotted': 1.0, 'random500_0': 1.0, 'overall': 1.0}\n",
      "INFO:tensorflow:Running param 1 of 4\n",
      "INFO:tensorflow:running zebra ['dotted', 'random500_1']\n",
      "INFO:tensorflow:Loaded /tmp/andre/tcav_class_test2/activations/acts_dotted_mixed4d shape (100, 14, 14, 528)\n",
      "INFO:tensorflow:/tmp/andre/tcav_class_test2/activations/acts_random500_1_mixed4d does not exist, Making one...\n",
      "INFO:tensorflow:Loaded /tmp/andre/tcav_class_test2/activations/acts_zebra_mixed4d shape (73, 14, 14, 528)\n",
      "INFO:tensorflow:Training CAV ['dotted', 'random500_1'] - mixed4d alpha 0.1\n",
      "INFO:tensorflow:training with alpha=0.1\n",
      "INFO:tensorflow:acc per class {'dotted': 0.9642857142857143, 'random500_1': 1.0, 'overall': 0.9818181818181818}\n",
      "INFO:tensorflow:CAV accuracies: {'dotted': 0.9642857142857143, 'random500_1': 1.0, 'overall': 0.9818181818181818}\n",
      "INFO:tensorflow:Running param 2 of 4\n",
      "INFO:tensorflow:running zebra ['random500_0', 'random500_1']\n",
      "INFO:tensorflow:Loaded /tmp/andre/tcav_class_test2/activations/acts_random500_0_mixed4d shape (87, 14, 14, 528)\n",
      "INFO:tensorflow:Loaded /tmp/andre/tcav_class_test2/activations/acts_random500_1_mixed4d shape (82, 14, 14, 528)\n",
      "INFO:tensorflow:Loaded /tmp/andre/tcav_class_test2/activations/acts_zebra_mixed4d shape (73, 14, 14, 528)\n",
      "INFO:tensorflow:Training CAV ['random500_0', 'random500_1'] - mixed4d alpha 0.1\n",
      "INFO:tensorflow:training with alpha=0.1\n",
      "INFO:tensorflow:acc per class {'random500_0': 0.4642857142857143, 'random500_1': 0.48148148148148145, 'overall': 0.4727272727272727}\n",
      "INFO:tensorflow:CAV accuracies: {'random500_0': 0.4642857142857143, 'random500_1': 0.48148148148148145, 'overall': 0.4727272727272727}\n",
      "INFO:tensorflow:Running param 3 of 4\n",
      "INFO:tensorflow:running zebra ['random500_1', 'random500_0']\n",
      "INFO:tensorflow:Loaded /tmp/andre/tcav_class_test2/activations/acts_random500_1_mixed4d shape (82, 14, 14, 528)\n",
      "INFO:tensorflow:Loaded /tmp/andre/tcav_class_test2/activations/acts_random500_0_mixed4d shape (87, 14, 14, 528)\n",
      "INFO:tensorflow:Loaded /tmp/andre/tcav_class_test2/activations/acts_zebra_mixed4d shape (73, 14, 14, 528)\n",
      "INFO:tensorflow:Training CAV ['random500_1', 'random500_0'] - mixed4d alpha 0.1\n",
      "INFO:tensorflow:training with alpha=0.1\n",
      "INFO:tensorflow:acc per class {'random500_1': 0.2857142857142857, 'random500_0': 0.6296296296296297, 'overall': 0.45454545454545453}\n",
      "INFO:tensorflow:CAV accuracies: {'random500_1': 0.2857142857142857, 'random500_0': 0.6296296296296297, 'overall': 0.45454545454545453}\n",
      "INFO:tensorflow:Done running 4 params. Took 35.41862964630127 seconds...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "import absl\n",
    "absl.logging.set_verbosity(0)\n",
    "num_random_exp=2\n",
    "## only running num_random_exp = 10 to save some time. The paper number are reported for 500 random runs. \n",
    "mytcav = tcav.TCAV(sess,\n",
    "                   target,\n",
    "                   concepts,\n",
    "                   bottlenecks,\n",
    "                   act_generator,\n",
    "                   alphas,\n",
    "                   cav_dir=cav_dir,\n",
    "                   num_random_exp=num_random_exp)#10)\n",
    "print ('This may take a while... Go get coffee!')\n",
    "results = mytcav.run(run_parallel=False)\n",
    "print ('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hjKVKa80YYdp",
    "outputId": "ff3cbebe-4edd-4342-cede-24dc10ce9d99",
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class = zebra\n",
      "  Concept = dotted\n",
      "    Bottleneck = mixed4d. TCAV Score = 0.54 (+- 0.02), random was 0.55 (+- 0.04). p-val = 0.895 (not significant)\n",
      "{'mixed4d': {'bn_vals': [0.01], 'bn_stds': [0], 'significant': [False]}}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEYCAYAAAD4czk4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAg6ElEQVR4nO3dedxUZf3/8dcbEBVREUFFdpFUsiJFoW9iZvYTzED7aWqloiZZ0jdNTbJNLcvM/Jpl4obKNxWXXMgwI3M3FcSlcOMOF25BBNw1Nv18/zjXrYdhZu5hGe6D9/v5eMzjPst1nXOdM3PPe84515xRRGBmZlYkbVq6AWZmZqUcTmZmVjgOJzMzKxyHk5mZFY7DyczMCsfhZGZmheNwsg8NSRtK+pOk1yVd19LtqUTSc5L2aul2rOsknSrpDxXm7SGpsc7rb9HnUdLlkn7WUuuvN4dTwUh6K/d4T9J/cuNflbSJpHMlvZCmNaTxLiXLuVPSq5LWT+OfkvS2pI3LrPMRSWMqtOcUSc+mdTVKuqY+W75GHABsCWweEQe2dGNam2phsS6RNErSvSXTPtRBUEQOp4KJiI5ND+AF4Iu58euA24GPAsOATYD/AhYCuzYtQ1IfYCgQwIi03H8AjcD/z69P0o7AAODq0rZIOhw4FNgrrX9QWv8aI6ndGlxcb+CZiFjWwu0ws9UVEX4U9AE8RxYMTeNfB+YBHZup92PgPuAc4Jbc9FOAv5eUPQu4ocJyfgecW2U9nYHLgDnAq8BNuXlHAw3AK8AkYOvcvACOBWYCz6Zp+wKPAq8B9wMfz5U/GXgReBN4GvhcmbacBiwBlgJvAUeRffj6IfA88DIwAdg0le+T2nEU2YeAuytsY7V2jQX+ndr1BLB/Sd2jgSdz83fKPa8nAo8DrwPXABtU2c+VlrMDcGdq2wxgRK7O5cD5wJ9TvQeBfrn5HwWmpOdnHnBKmt4mt10LgWuBziX7bHR6zucCJ6R5w0r2/2MVtqXiPgNGAfcCZ5O9np4Fhufm9wXuSnWnkL0+/1BhPXuQfRg7BViQ9vlXc/M3Ta+H+en18cO07TsAi4B303a8lrZ3adq+t4A/lf5/1rjfDid7rS0AfpBrS8W6af5uZK+914DZwKjcc/yzNLwxcAdwHqCWfu9aE48Wb4AfVZ6cFcNpInBFDfUagG8BO6d/qi3T9J5pvFcab5P+gfersJyvkb15nUR21NS2ZP6fyd5YNwPWAz6Tpu+Z/gF3AtYHfkvuzT/9o04hC7cNU7mXgcFA2/RP/Fyqu136h9w61e1D7k22pD2nknuzAo5M+2IboCNwA/C/ueUE2RvURsCGZZZXsV1p/oHA1mk/HgS8DXTLzXsR2AUQsC3QO/e8PpTqdiYLnmMqbFPZ5aT93UD25ts+7fM3ge1SvcvTc7cr0A64EpiY5m1MChZggzQ+OM07DngA6JH2/4XA1SX77Oq0zz5G9ua+V7n9X2V7Ku2zUWSvz6PT/v4mWQgqzf8H2Qeu9YHd0/ZWC6dlufKfSetq2j8TgJvTtvcBngGOyrXj3pLlXU4KgnL/nzXut4vJXu+fABYDO9RQt1fazkPSc745MDDfpjTtodL2reuPFm+AH1WenBXDaQpwZjN1dkv/4F3S+FPA8bn5f+ODT8mfJwuR9aos76upzttkn+rGpundgPeAzcrUuRQ4KzfeMbWpTxoPYM/c/AuAn5Ys4+n0hrItWUDsVa2dqc6pLB9OtwPfyo1vl9rRLveGsU2V5VVsV4XyjwIj0/BtwHeqPK9fy42fBYyrULbscshO274EtMlNuxo4NQ1fDlySm7cP8FQaPgR4pML6niR3ZJqe59J9tn1J2y8tt/9rfI3n99kooCE3r0Na31Zkb9LLgI1y86+qtD4+CKd8+WuBH5EF32JgQG7eN4A7c+1Y2XCqZb/1yM1/CDi4hrrfB26ssI2XA+OBfwEnrcx+Xxcevua0bllI9sKt5nDgrxGxII1flaY1uQI4LA0fClwVEUsrLSwiroyIvYBOwDHA6ZL2JjsKeyUiXi1TbWuyUyVNy3grtb17rszs3HBv4ARJrzU90vK3jogGsk+WpwIvS5ooaevKm1+5HWm4HVmniXLtKFWxXQCSDpP0aG7ejkBTx5SeZKdpKnkpN/wOWYCXU2k5WwOzI+K93LTnWX4fV1pHtbb1Bm7MbdOTZKe4Ku2z51NbatLMPluuzRHxThrsmNbxakS8XbLuasqV3zqtrz0rvjby+25l1bLfKj0f1eo29zr6AtnR2LjVaHshOZzWLX8D9pa0UbmZkjYEvgx8RtJLkl4Cjgc+IekTqdgNQHdJnwW+RHZ6o1kRsTQiriO7TrIj2RtUZ0mdyhSfQ/YP19SujchOPbyYX2RueDZwRkR0yj06RMTVad1XRcRuaZkB/LKWNpe2gw8+fc+r0I5SFdslqTfZaZoxZL0DO5F9glWubr8a21lNpeXMAXpKyv8P92L5fbyyy2yaN7xkmzeIiPxye5asc04arrYvqWGfVTMX2Kzktd+rmTrlys8hO1uwlBVfG03bWG47qm4bte23Vanb3OvoYuAvwORK7wvrKofTuuV/yV6sf5S0vaQ2kjZP3b33AfYj+8Q1ABiYHjsA95COltInyevJOjI8HxHTKq0sdan9gqSN07qGk11IfzAi5gK3Ar+XtJmk9STtnqpeBRwhaWDqyv7zVOe5Cqu6GDhG0mBlNsqtdztJe6blLAL+k7axFlcDx0vqK6ljasc1UXtvvortIrvmEmTXXJB0BFloN7kEOFHSzqnutunNeWVVWs6DZKdav5f2/R7AF8muSzbnFmArScdJWj/t58Fp3jjgjKa2SuoqaWRJ/R9J6iDpo8ARZNcdIQv9PiWBmdfcPqsoIp4HpgGnSWovabe0vc1pKj+UrHPLdRHxLtkpvjPStvcGvgs0dYOfB/SQ1D63nHlk1y4rqWW/rUrdK4G9JH1ZUrv0/z6wpP4YstPNt6QPqB8KDqd1SEQsJrv28hTZ9ac3yM5ddyF7szocuCwiXoiIl5oeZL2avprrLn0F2afG5o6a3iC74P4CWU+hs4BvRkTTd0AOJfsE+hTZdaHjUjtvJzu3/0eyT7z9gIOrbNc0sovgvyPrpdVAdt4fsgvEZ5J92n0J2CK1qRbjyQL9brKeX4uAb9dYt2q7IuIJ4NdkF+nnkXUOuC9X9zrgDLKgfhO4iazzw0qptJyIWEL2NYHhZPvm98BhEfFUDct8k+x64xfJ9ulM4LNp9m/Ielf+VdKbZBfqB5cs4i6yfXE7cHZE/DVNb/ri80JJ08ust+o+q8FXUlteAX5C86/fl8ietzlkb/LH5PbPt8nCfRZZD8GryF4vAH8n6/34kqSm0+OXAgPSqbebyqyrlv1WScW6EfEC2fXCE9J2P0rWoeJ9kV2AGk32wfVmSRvUuN5Ca+oFY2ZWlbLvzz1L1jFlpb9LZrYyfORkZmaF43AyM7PC8Wk9MzMrHB85mZlZ4bSKm1126dIl+vTp09LN+NB7e5s9WNxtIJ3vO7elm2Jm64iHH354QUR0LZ3eKsKpT58+TJtW8es8thrumTmfh59/laN268sl9zzL9Q83ct+0aUx5Yh6Pzn6Vk/bevqWbaGYFJqnsnT5aRThZfd02Yx6X3/8cPTfrwBuLljLy/PuYNf8tjvh0XyICqZYbAJiZfcDhZKtlaP+uTP7vLpxy47+4+qEXAFjw5mIm//dQenbu0MKtM7N1lTtE2Gq5v2EB+/72Xm7911w+1n1TNt6gHV06tmef8+7hf6Y8g3uDmtmq8JGTrZYl777HnttvwdG7b8Ol6ZrTzWN24y//eolHZ7/mU3r2obJ06VIaGxtZtGhRSzdlnbPBBhvQo0cP1ltvvZrKO5xsteyx3Rbssd0WK0wftuNWDNtxqxZokVn9NDY2svHGG9OnTx9/8FoJEcHChQtpbGykb9++NdXxaT1bY47//Ee4b+yeLd0Ms7pZtGgRm2++uYNpJUli8803X6kjzrqGk6Rhkp6W1CBpbJn5knRemv+4pJ1y88ZLelnSv0rqdJY0RdLM9Hezem6DmVmeg2nVrOx+q1s4SWoLnE92S/8BwCGSBpQUGw70T4/RZD+L3eRyYFiZRY8Fbo+I/mS37F8h9MzMbN1Wz2tOuwINETELQNJEYCTwRK7MSGBC+j2SByR1ktQtIuZGxN3pFv2lRgJ7pOErgDuBk+uzCWZmlfUZ++c1urznzvzCGlnOpEmTeOKJJxg7dvU+u995552cffbZ3HLLLe9Pmzp1KkOGDOGaa67hgAMOWKHOqaeeSseOHTnxxBNXa931DKfuZD9+1aSRFX98q1yZ7mQ/UFfJlulXWImIuZJWvBpvZtaKjRgxghEjRqzx5b777rucfPLJ7L333mt82aXqGU7lTjCWfumlljKrtnJpNNmpQnr16rVay1rTn47MbN108YhuLG18rW7Lf7yGZb84+wW+degBfHKXITw+fSrbDdiRkV/+Khec8wteWbCAn593EbNmPs2Mxx/hlJ/9iu8c+RX22mcEXzzgYK77w2VMf/B+fvHbi7n/rr9zwTlnsmTJYnr27svpv/4dHTbqyH13/I2zTjuFTp07s8OOn+CNRUvfb9cfLrmAIXsOZ8Zjj/D8wrffb9MZZ5zBhAkT6NmzJ127dmXnnXde7X1Rzw4RjUDP3HgPsp9LXtkypeZJ6gaQ/r5crlBEXBQRgyJiUNeuK9xT0MxsnTX7uVl89chvcP2U+3j23zOZfNP1XH7DX/juD3/Kpb87Z7myP/7luVx47llMf/B+Jlx0PmNPP4tXX1nIxeedzYVX38g1t97FgI8PZMLFv2fxokWcdvJ3OO+yq7n8j7eycP4Hb6/z5s7h73+5hQMPPXK55T/88MNMnDiRRx55hBtuuIGpU6eukW2sZzhNBfpL6iupPXAwMKmkzCTgsNRrbwjwetMpuyomAYen4cOBm9dko83Miq57z9703+GjtGnThn4f2Z7Bu+2OJPpvP4A5jS8sV3bzrlvwrRO+z9cPGsEJP/opm262GY9Pn8qsmU8zav9hfHnvofzp+onMbZzNs/+eSfeevendtx+S+ML+B76/nF+ddgrHnXIqbdu2XW7599xzD/vvvz8dOnRgk002WWOnE+t2Wi8ilkkaA9wGtAXGR8QMScek+eOAycA+QAPwDnBEU31JV5N1fOgiqRH4SURcCpwJXCvpKOAF4IO9Z2bWCqzXvv37w23Uhvbt1wdAbdqwbNmyFcrPfPoJNt2sM/PnvQRkX4odMnQPfnn+pcuVe2rGPyt2+Z7x+COcfOxRALz6yivcc8cU+m25abbeOnSvr+sdIiJiMlkA5aeNyw0HcGyFuodUmL4Q+NwabKaZ2YfWPx95mPvu+BvX3HoXRx24L5/afU8+vtMu/OKHJ/HCs7Po1Xcb/vOfd5g3dw59+/XnxdnPM/u5Z+nZpy+33vzH95dz6/2PvT/8o+O/xe577c1+++3H9OnTGTVqFGPHjmXZsmX86U9/4hvf+MZqt9u3LzIzW0WTxny6pZtQ1ZLFizn95O9w+q/PZ4utunHCj37KT04cwyXXTOL0c37P2DFfZ8mSxQCMOekH9NlmW3585rmMGXUQnTp35pO7DKHh6SerrmOnnXbioIMOYuDAgfTu3ZuhQ4eukbarNdw1etCgQbE6Pzbo3npmBllvvS17bdPSzSiMj/fotFLln3zySXbYYYflpkl6OCIGlZb1vfXMzKxwHE5mZlY4DiczsxoF4R/QXEUru98cTmZmNXr+taUse+cNB9RKavo9pw022KDmOu6tZ2ZWo98++CrfBnp3WoDK3n2tdXnyzQ1rLtv0S7i1cjiZmdXojcXvccbdC1u6GYWxpu6iXo5P65mZWeE4nMzMrHAcTmZmVjgOJzMzKxyHk5mZFY7DyczMCsfhZGZmheNwMjOzwnE4mZlZ4TiczMyscBxOZmZWOA4nMzMrHIeTmZkVjsPJzMwKx+FkZmaF43AyM7PCcTiZmVnhOJzMzKxwHE5mZlY4DiczMysch5OZmRWOw8nMzArH4WRmZoXjcDIzs8JxOJmZWeE4nMzMrHAcTmZmVjgOJzMzK5y6hpOkYZKeltQgaWyZ+ZJ0Xpr/uKSdmqsraaCkByQ9KmmapF3ruQ1mZrb21S2cJLUFzgeGAwOAQyQNKCk2HOifHqOBC2qoexZwWkQMBH6cxs3M7EOknkdOuwINETErIpYAE4GRJWVGAhMi8wDQSVK3ZuoGsEka3hSYU8dtMDOzFtCujsvuDszOjTcCg2so072ZuscBt0k6myxc/6vcyiWNJjsao1evXqu0AWZm1jLqeeSkMtOixjLV6n4TOD4iegLHA5eWW3lEXBQRgyJiUNeuXWtsspmZFUE9w6kR6Jkb78GKp+AqlalW93DghjR8HdkpQDMz+xCpZzhNBfpL6iupPXAwMKmkzCTgsNRrbwjwekTMbabuHOAzaXhPYGYdt8HMzFpA3a45RcQySWOA24C2wPiImCHpmDR/HDAZ2AdoAN4BjqhWNy36aOA3ktoBi0jXlczM7MOjnh0iiIjJZAGUnzYuNxzAsbXWTdPvBXZesy01M7Mi8R0izMyscBxOZmZWOA4nMzMrHIeTmZkVjsPJzMwKx+FkZmaF43AyM7PCcTiZmVnhOJzMzKxwHE5mZlY4DiczMysch5OZmRWOw8nMzArH4WRmZoXjcDIzs8JxOJmZWeE4nMzMrHAcTmZmVjgOJzMzKxyHk5mZFY7DyczMCsfhZGZmheNwMjOzwnE4mZlZ4TiczMyscBxOZmZWOA4nMzMrHIeTmZkVjsPJzMwKp9lwktRB0o8kXZzG+0vat/5NMzOz1qqWI6fLgMXAp9J4I/CzurXIzMxavVrCqV9EnAUsBYiI/wCqa6vMzKxVqyWclkjaEAgASf3IjqTMzMzqol0NZX4C/AXoKelK4NPAqHo2yszMWreq4SSpDbAZ8CVgCNnpvO9ExIK10DYzM2ulqp7Wi4j3gDERsTAi/hwRt6xMMEkaJulpSQ2SxpaZL0nnpfmPS9qplrqSvp3mzZB0Vq3tMTOzdUMtp/WmSDoRuAZ4u2liRLxSrZKktsD5wOfJevhNlTQpIp7IFRsO9E+PwcAFwOBqdSV9FhgJfDwiFkvaosZtNTOzdUQt4XRk+ntsbloA2zRTb1egISJmAUiaSBYq+XAaCUyIiAAekNRJUjegT5W63wTOjIjFABHxcg3bYGZm65Bme+tFRN8yj+aCCaA7MDs33pim1VKmWt2PAEMlPSjpLkm7lFu5pNGSpkmaNn/+/Bqaa2ZmRdHskZOk9ciOVnZPk+4ELoyIpc1VLTMtaixTrW47sk4aQ4BdgGslbZOOvj4oHHERcBHAoEGDStdrZmYFVstpvQuA9YDfp/FD07SvN1OvEeiZG+8BzKmxTPsqdRuBG1IYPSTpPaAL4MMjM7MPiVrCaZeI+ERu/O+SHquh3lSgv6S+wIvAwcBXSspMAsaka0qDgdcjYq6k+VXq3gTsCdwp6SNkQeau7WZmHyK1hNO7kvpFxL8BJG0DvNtcpYhYJmkMcBvQFhgfETMkHZPmjwMmA/sADcA7wBHV6qZFjwfGS/oXsAQ4vPSUnpmZrdtqCaeTgDskzSK7FtSbFCLNiYjJZAGUnzYuNxws3wuwat00fQnwtVrWb2Zm66ZmwykibpfUH9iOLJyeaurGbWZmVg+1/J7TscCGEfF4RDwGdJD0rfo3zczMWqta7kp+dES81jQSEa8CR9etRWZm1urVEk5tJL3/vaN0a6H29WuSmZm1drV0iLiN7Iuu48i+CHsM2U9omJmZ1UUt4XQyMJrsLhEC/gpcUs9GmZlZ61ZLb733gHGSxgMfBV6MiGa/52RmZraqKl5zkjRO0kfT8KbAo8AE4BFJh6yd5pmZWWtUrUPE0NxdGY4AnomIjwE7A9+re8vMzKzVqhZOS3LDnye7px0R8VI9G2RmZlYtnF6TtK+kTwKfJvXQk9QO2HBtNM7MzFqnah0ivgGcB2wFHJc7Yvoc8Od6N8zMzFqviuEUEc8Aw8pMv43su09mZmZ1UcsdIszMzNYqh5OZmRVOte85bbk2G2JmZtak2pHTY5KmSDoyfQnXzMxsragWTt2Bs4GhwDOSbpJ0kCR3Izczs7qqGE4R8W5E3BYRRwA9gcuA/YBnJV25ltpnZmatUE0dIiJiCfAE8CTwBjCgno0yM7PWrWo4Seol6SRJ04FbgLbAyIj45FppnZmZtUoVv4Qr6X6y607XAaMjYtpaa5WZmbVq1W5f9H3g7oiIpgmS+gGHAAdHxI71bpyZmbVO1TpE3BURIambpOMkPQTMIDu1599zMjOzuqn2JdyjJf0duAvoAnwdmBsRp0XEP9dWA83MrPWpdlrvfOAfwFearjdJiirlzczM1ohq4bQ1cCBwTrqV0bXAemulVWZm1qpVu+a0ICIuiIjdyX7D6XXgZUlPSvr5WmuhmZm1OrV+CbcxIs6OiJ2BkcDi+jbLzMxas2odIr4m6dAysz4DzKxfk8zMrLWrduR0AnBTmekT0zwzM7O6qBZObSPizdKJaZo7RpiZWd1UC6f1JG1UOlHSxkD7+jXJzMxau2rhNB64XlKfpglpeCJwaX2bZWZmrVm17zkdAlwI3CWpY5r2FnBmRFxQ95aZmVmrVS2cFBEXAhemcFK5a1BmZmZrWrVw6irpu/kJkt4fjohzmlu4pGHAb8huFntJRJxZMl9p/j7AO8CoiJheY90TgV8BXSNiQXNtMTOzdUe1cGoLbLyqC5bUluz+fJ8HGoGpkiZFxBO5YsOB/ukxGLgAGNxcXUk907wXVrV9ZmZWXNXCaW5EnLYay94VaIiIWQCSJpLdXSIfTiOBCek3ox6Q1ElSN6BPM3X/B/gecPNqtM/MzAqqWm89VZlXi+7A7Nx4Y5pWS5mKdSWNAF6MiMeqrVzSaEnTJE2bP3/+qm2BmZm1iGrh9LnVXHa5cCv9yY1KZcpOl9QB+AHw4+ZWHhEXRcSgiBjUtWvXZhtrZmbFUe2u5K+s5rIbgZ658R7AnBrLVJreD+gLPCbpuTR9uqStVrOtZmZWIDXdlXwVTQX6S+orqT1wMDCppMwk4DBlhgCvR8TcSnUj4p8RsUVE9ImIPmQhtlNEvFTH7TAzs7WsWoeI1RIRyySNAW4j6/k3PiJmSDomzR8HTCbrRt5A1pX8iGp169VWMzMrlrqFE0BETCYLoPy0cbnhAI6ttW6ZMn1Wv5VmZlY09TytZ2ZmtkocTmZmVjgOJzMzKxyHk5mZFY7DyczMCsfhZGZmheNwMjOzwnE4mZlZ4TiczMyscBxOZmZWOA4nMzMrHIeTmZkVjsPJzMwKx+FkZmaF43AyM7PCcTiZmVnhOJzMzKxwHE5mZlY4DiczMysch5OZmRWOw8nMzArH4WRmZoXjcDIzs8JxOJmZWeE4nMzMrHAcTmZmVjgOJzMzKxyHk5mZFY7DyczMCsfhZGZmheNwMjOzwnE4mZlZ4TiczMyscBxOZmZWOA4nMzMrnLqGk6Rhkp6W1CBpbJn5knRemv+4pJ2aqyvpV5KeSuVvlNSpnttgZmZrX93CSVJb4HxgODAAOETSgJJiw4H+6TEauKCGulOAHSPi48AzwPfrtQ1mZtYy6nnktCvQEBGzImIJMBEYWVJmJDAhMg8AnSR1q1Y3Iv4aEctS/QeAHnXcBjMzawH1DKfuwOzceGOaVkuZWuoCHAncWm7lkkZLmiZp2vz581ey6WZm1pLqGU4qMy1qLNNsXUk/AJYBV5ZbeURcFBGDImJQ165da2iumZkVRbs6LrsR6Jkb7wHMqbFM+2p1JR0O7At8LiJKA8/MzNZx9Txymgr0l9RXUnvgYGBSSZlJwGGp194Q4PWImFutrqRhwMnAiIh4p47tNzOzFlK3I6eIWCZpDHAb0BYYHxEzJB2T5o8DJgP7AA3AO8AR1eqmRf8OWB+YIgnggYg4pl7bYWZma189T+sREZPJAig/bVxuOIBja62bpm+7hptpZmYF4ztEmJlZ4TiczMyscBxOZmZWOA4nMzMrHIeTmZkVjsPJzMwKx+FkZmaF43AyM7PCcTiZmVnhOJzMzKxwHE5mZlY4DiczMysch5OZmRWOw8nMzArH4WRmZoXjcDIzs8JxOJmZWeE4nMzMrHAcTmZmVjgOJzMzKxyHk5mZFY7DyczMCsfhZGZmheNwMjOzwnE4mZlZ4TiczMyscBxOZmZWOA4nMzMrHIeTmZkVjsPJzMwKx+FkZmaF43AyM7PCcTiZmVnhOJzMzKxwHE5mZlY4DiczMyucuoaTpGGSnpbUIGlsmfmSdF6a/7iknZqrK6mzpCmSZqa/m9VzG8zMbO2rWzhJagucDwwHBgCHSBpQUmw40D89RgMX1FB3LHB7RPQHbk/jZmb2IVLPI6ddgYaImBURS4CJwMiSMiOBCZF5AOgkqVszdUcCV6ThK4D96rgNZmbWAtrVcdndgdm58UZgcA1lujdTd8uImAsQEXMlbVFu5ZJGkx2NAbwl6elV2QgzMytPv6QLsGA1F9O73MR6hpPKTIsay9RSt6qIuAi4aGXqmJlZ7SRNi4hB9Vh2PU/rNQI9c+M9gDk1lqlWd1469Uf6+/IabLOZmRVAPcNpKtBfUl9J7YGDgUklZSYBh6Vee0OA19Mpu2p1JwGHp+HDgZvruA1mZtYC6nZaLyKWSRoD3Aa0BcZHxAxJx6T544DJwD5AA/AOcES1umnRZwLXSjoKeAE4sF7bYGZmVdXt0okiVupSjpmZWd35DhFmZlY4DiczMysch5OZmQEg6VRJJ1aZP0rS1rnx4yR1WMl17CHplubKOZzMzKxWo4Ctc+PHASsVTrVyOJmZtWKSfpBusv03YLs0baCkB9INuW+UtJmkA4BBwJWSHpX0HbKgukPSHane/5P0D0nTJV0nqWOaPkzSU5LuBb5UU7vcW8/MrHWStDNwOdnt4doB04FxwGHAtyPiLkmnA5tExHGS7gROjIhpqf5zwKCIWCCpC3ADMDwi3pZ0MrA+cBYwE9iT7GtD1wAdImLfam2r5+2LzMys2IYCN0bEOwCSJgEbAZ0i4q5U5grguhqWNYTsVyTukwTQHvgHsD3wbETMTOv4Ax/c97Qih5OZWeu2pk6fCZgSEYcsN1EauCrr8DUnM7PW625gf0kbStoY+CLwNvCqpKGpzKFA01HUm8DGufr58QeAT0vaFkBSB0kfAZ4C+krql8otF16V+MjJzKyViojpkq4BHgWeB+5Jsw4HxqVu4rNIt5Yjuz41TtJ/gE+R3b7oVklzI+KzkkYBV0taP5X/YUQ8k37C6M+SFgD3Ajs21zZ3iDAzs8LxaT0zMysch5OZmRWOw8nMzArH4WRmZoXjcDIzs8JxOJmZWeE4nMzMrHD+D+tpTUu95wQpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils_plot.plot_results(results, num_random_exp=num_random_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cav_key': 'dotted-random500_0-mixed4d-linear-0.1',\n",
       "  'cav_concept': 'dotted',\n",
       "  'negative_concept': 'random500_0',\n",
       "  'target_class': 'zebra',\n",
       "  'cav_accuracies': {'dotted': 0.9655172413793104,\n",
       "   'random500_0': 1.0,\n",
       "   'overall': 0.9827586206896551},\n",
       "  'i_up': 0.9142857142857143,\n",
       "  'val_directional_dirs_abs_mean': 0.0015300690759762696,\n",
       "  'val_directional_dirs_mean': -0.0004906266604890594,\n",
       "  'val_directional_dirs_std': 0.004774616357160364,\n",
       "  'val_directional_dirs': [-1.5607520682126632e-06,\n",
       "   -0.0003470333080822435,\n",
       "   -1.2200798401710618e-06,\n",
       "   -1.2157380126315303e-05,\n",
       "   0.026448860369208273,\n",
       "   -5.697981594678126e-06,\n",
       "   -3.328996276994093e-06,\n",
       "   -2.1760676884742763e-05,\n",
       "   -3.133844947808763e-05,\n",
       "   -1.8391095244559554e-06,\n",
       "   -1.539228078990107e-05,\n",
       "   -4.001580928247186e-05,\n",
       "   -4.2512053270955787e-07,\n",
       "   -0.00018122185936304854,\n",
       "   -3.8517221093360524e-07,\n",
       "   -0.0003485580969638108,\n",
       "   -5.543859508326695e-06,\n",
       "   -0.001401730520679811,\n",
       "   -0.0002971633317846113,\n",
       "   -8.066816919092226e-06,\n",
       "   -5.3306740092626826e-05,\n",
       "   -1.757322493029769e-05,\n",
       "   -1.802618452423861e-05,\n",
       "   0.00010071709973603106,\n",
       "   -2.8967424320764633e-06,\n",
       "   -3.0560310550067773e-06,\n",
       "   -6.149499127796183e-05,\n",
       "   -2.7621243579194775e-06,\n",
       "   -3.5828463856912824e-05,\n",
       "   -1.0491220252701265e-07,\n",
       "   -0.0001981161382972712,\n",
       "   -2.2077522442555458e-07,\n",
       "   -1.634780721493973e-05,\n",
       "   -1.2272161038916113e-05,\n",
       "   -7.435691657645472e-07,\n",
       "   -0.010775760709706967,\n",
       "   -2.2596806082518787e-05,\n",
       "   -4.9719511070259415e-08,\n",
       "   -0.0134454757687661,\n",
       "   -4.2605291433358385e-05,\n",
       "   -0.0005654744569764733,\n",
       "   -1.0878602295949537e-05,\n",
       "   -6.623575432908722e-07,\n",
       "   -7.30282036272568e-06,\n",
       "   -4.140901509961089e-05,\n",
       "   -0.0186682533844547,\n",
       "   -8.203126822194137e-08,\n",
       "   4.403596534427462e-08,\n",
       "   -0.010599542173686242,\n",
       "   -0.0015587392751073073,\n",
       "   -0.00010795295502439053,\n",
       "   -7.071426111969921e-05,\n",
       "   -0.0011009782568011234,\n",
       "   -0.00967497349580535,\n",
       "   -0.0002997139642511521,\n",
       "   4.059094077946611e-09,\n",
       "   -7.071760506238352e-05,\n",
       "   -8.241477434298217e-07,\n",
       "   -0.0002231934746633346,\n",
       "   -0.00021629018268365076,\n",
       "   -3.0626448251878465e-07,\n",
       "   0.006766095960323864,\n",
       "   -1.041457999935546e-05,\n",
       "   0.0030647630177247634,\n",
       "   -1.8794553794652724e-05,\n",
       "   -2.152560078005161e-07,\n",
       "   -2.750167986403422e-07,\n",
       "   -3.413098167638148e-07,\n",
       "   -1.114699014023577e-05,\n",
       "   -3.1476582215981794e-05],\n",
       "  'note': 'alpha_0.1 ',\n",
       "  'alpha': 0.1,\n",
       "  'bottleneck': 'mixed4d',\n",
       "  'cav_instances': <tcav.cav.CAV at 0x1c55ab18610>}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Run TCAV.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
